# 統計的機械学習
- Kosuke Toda (@SeeKT)
### 参考
- 金森，統計的学習理論，講談社，2015．
- 金森，Pythonで学ぶ統計的機械学習，オーム社，2018．

## 統計的学習理論の枠組
### 問題設定
過去の経験と将来の出来事との間の繋がりに関して，どのような関連を仮定できるか，何を目標とするのかによってさまざまな問題設定が考えられる．このような問題は確率的な問題として定式化される．

このように定式化された問題を解いて，観測された事象から役に立つ情報を抽出し利用することを，「学習する」と表現する (統計学における推定や予測とほぼ同義だが，アルゴリズム的な視点により重点が置かれる)．

#### 用語
- データ
    - 観測によって得られる情報
    - 将来得られる情報もデータという用語を用いる
- 学習データ
    - 学習に用いられるデータ
    - 仮説のパラメータなどを推定するために直接用いられるデータ
- 検証データ
    - 学習結果の性能を検証するためのデータ
    - 主に学習アルゴリズムに含まれる正則化パラメータなどを調整するために用いられる．
- 観測データ
    - 通常，学習データと検証用データを合わせたデータ
- テストデータ
    - 学習アルゴリズムの予測精度を評価するためのデータ
    - 多くの場合，学習における主要な目標は，テストデータに対して高い予測精度を達成すること
    - データを学習データ，検証用データ，テストデータに分ける．学習データ，検証用データで学習を行い，テストデータで学習結果の性能を評価する．
- 入力データ・出力データ・ラベル
    - データが入力と出力の組で表されるとき，データの入力部分を入力データ，出力部分を出力データという．
    - 入力が$x$，出力が$y$のとき，入出力データを$(x, y)$と表す．
    - 入力空間$\mathcal{X}$: 入力$x$がとり得る値の集合
    - 出力値の集合$\mathcal{Y}$
        - 出力データが有限集合に値をとるとき，その値をラベルという．
- 仮説
    - 入力空間から出力集合への関数を仮説といい，仮説の集合を仮説集合という．
    - 学習アルゴリズムは，学習データ/観測データを仮説に変換する関数とみなすこともできる．
- 判別器・判別関数
    - 有限集合に値をとる仮説を判別器という．
    - 判別器を記述するために用いられる実数値関数やベクトル値関数を判別関数という．
        - e.g. 出力が2値ラベルのとき，判別関数$f: \mathcal{X} \to \mathbb{R}$を用いて判別器$h: \mathcal{X} \to \{+1, -1\}$を$h(x) = \mathrm{sign}(f(x))$と表す．
        - 判別関数を用いることで，仮説集合のモデリングや記述が簡単になることがある．
- 損失関数
    - 出力値と予測結果の間の誤差を測る関数
    - 損失関数の値が大きいほど，誤差や損失が大きいことを意味する．

機械学習の主要なテーマは，観測データから適切な仮説を学習するアルゴリズムを設計すること．
統計的機械学習とは，学習アルゴリズムにより得られる仮説の予測精度を評価し，性能を向上させるための指針を与える理論的枠組．
以下で，統計的学習理論で扱う代表的な問題設定を紹介する．

##### 判別問題
出力が有限集合$\mathcal{Y}$のラベルに値をとるとき，入力データから対応するラベルを予測する問題．
- $|\mathcal{Y}| = 2$のとき，2値判別問題．
- $|\mathcal{Y}| \geq 3$のとき，多値判別問題．

2値判別について
データからラベルを予測するための判別境界を学習する．
基本的な学習アルゴリズム: サポートベクトルマシン，ブースティング

判別問題の例: 迷惑メールの分類
入力データ: メールのテキストデータ
出力ラベル: 迷惑メール("spam")と通常メール("non-spam")
予測ラベルを$\hat{y}$，真のラベルを$y$とするとき，代表的な損失関数として，以下の式で定義される$0$-$1$損失がある．
$$
\ell_{\text{err}}(\hat{y}, y) = \boldsymbol{1}[\hat{y} \neq y] = \begin{cases}
1, & y \neq \hat{y} \\
0, & y = \hat{y}
\end{cases}
$$

損失が真のラベル$y$に依存することもある(e.g. クレジットカード会社が顧客の購買履歴から将来の支払いが可能かどうかを判別する)．
$\Rightarrow$ 間違い方によって被る損失が異なる
この場合は，$0$-$1$損失を拡張した損失
$$
\ell(\hat{y}, y) = \begin{cases}
\ell_y, & y \neq \hat{y} \\
0, & y = \hat{y}
\end{cases}
$$
を考える．適切に$\ell_y$の値を定めることで，単に間違いの数ではなく，目的に即した損失を小さくするように学習を行うことができる．

##### 回帰問題
出力が実数値をとるとき，入力データから出力を予測する問題
例: 株価や電力需要の予測

出力と完全に一致する値を予測することは，通常できない
$\Rightarrow$ 損失関数として2乗損失がよく用いられる．真の出力$y$に対する予測値が$\hat{y}$のとき，
$$
\ell(\hat{y}, y) = (\hat{y} - y)^2
$$
と定義される．
適当な統計モデルを設定し，2乗損失のもとに最適な関数を学習する．この結果を用いて，将来の入力$x$に対する出力$y$の値を予測する．

##### ランキング関数
出力: 2つの入力データの組$(x, x^{\prime}) \in \mathcal{X}^2$に対して，$x$の方が$x^{\prime}$より好ましければ$y = +1$，そうでなければ$y = -1$という出力ラベルが観測される．
$\Rightarrow$ 入出力データとして$(x, x^{\prime}, y)$が得られる．

ランキング問題: $x$の方が好ましければ$h(x) > h(x^{\prime})$，そうでなければ$h(x) \leq h(x^{\prime})$となるような関数$h: \mathcal{X} \to \mathbb{R}$を学習する．

入力$x, x^{\prime}$に対応する関数値を$h_1 = h(x), h_2 = h(x^{\prime})$とするとき，
$\hat{h} = (h_1, h_2) \in \mathbb{R}^2$と出力ラベル$y \in \{+1, -1\}$に対する損失として，$0$-$1$損失
$$
\ell(\hat{h}, y) = \begin{cases}
1, & y(h_1 - h_2) \leq 0 \\ 
0, & \text{otherwise}
\end{cases}
$$
などが用いられる．
入力$(x, x^{\prime})$に対するラベル$y$を$h(x) - h(x^{\prime})$の符号で予測すると解釈すれば，損失$\ell(\hat{h}, y)$のもとでランキング問題を判別問題として扱うことができる．
より一般に，複数の入力データ$(x_1, x_2, \ldots)$が与えられたとき，出力$y$として，入力データ間の選好に関する半順序関係を表す有向グラフを考えることもある．

例: ウェブ検索
ある検索ワードに対して，検索エンジンが検索結果のページ一覧$(x_1, x_2, \ldots)$を返す．このとき，ユーザが選んだページ$x_i$は他のページより好ましいことになる．ユーザの選好を考慮することで，好ましいと予測されるページをより上位に表示するなど，利便性を高めることができる．

例: コンピュータによる将棋の対戦
候補となる手の良し悪しを判定する問題は，ランキング問題として定式化される．選好を表す関数$h(x)$をデータ (過去の系譜) から学習することで，コンピュータ将棋の棋力が近年大きく向上している．

### 予測損失と経験損失
統計的学習理論では，主に予測損失と経験損失の2種類の損失を扱う．
$\Rightarrow$ これらの損失の関係を調べることで，学習アルゴリズムの予測精度などを定量的に評価できる．

確率的に値をとる入出力データを確率変数で表す．データ$(X, Y)$がしたがう確率分布$D$の下での期待値を$\mathbb{E}_{(X, Y) \sim D}[\cdot]$と表す．簡単のため，誤解のないときは$\mathbb{E}_D[\cdot]$や$\mathbb{E}[\cdot]$と表す．

#### 予測損失
損失関数として$\ell(\hat{y}, y)$を用いるとする．仮説$h$の予測損失$R(h)$を，テストデータ$(X, Y)$の分布における予測値$h(X)$の損失の期待値
$$
R(h) = \mathbb{E}_{(X, Y) \sim D}[\ell(h(X), Y)]
$$
と定義する．とくに，$0$-$1$損失$\ell_{\text{err}}$から定まる予測損失を$R_{\text{err}}(h)$と表し，予測判別誤差とよぶ．

学習における通常の問題設定では，データの分布は未知なので予測損失を計算することはできない
$\Rightarrow$ 観測データだけから，予測損失をできるだけ小さくする仮説を求めることが目標

#### 経験損失
データ$(X_1, Y_1), \ldots, (X_n, Y_n)$が観測されたとき，入出力関係を仮説$h$で説明することを考える．
損失関数$\ell(\hat{y}, y)$を用いて誤差を測るとき，観測データに対する仮説$h$の経験的損失$\hat{R}(h)$を，予測値$h(X_i)$と観測値$Y_i$との損失の平均値として，
$$
\hat{R}(h) = \frac{1}{n} \sum_{i = 1}^n \ell(h(X_i), Y_i)
$$
と定義する．
経験損失は観測データから計算することができる．とくに，$0$-$1$損失$\ell_{\text{err}}$から定まる経験損失を$\hat{R}_{\text{err}}(h)$と表し，経験判別誤差とよぶ．

#### 予測損失と経験損失の関係
入出力空間$\mathcal{X} \times \mathcal{Y}$上の分布に関する期待値を用いて経験損失を表すこともできる．
データ数が$n$のとき，確率$1/n$で$(X_i, Y_i)$に値をとる確率変数を$(X, Y)$とする．この分布を$\hat{D}$と表し，経験分布と呼ぶ．このとき経験損失は，
$$
\hat{R}(h) = \mathbb{E}_{(X, Y) \sim \hat{D}}[\ell(h(X), Y)]
$$
と表せる．
$\Rightarrow$ 予測損失と経験損失の違いは，期待値を計算するときの確率分布の違い．

各データ$(X_i, Y_i)$が同一の分布$D$に従うとき，経験損失の期待値は予測損失に一致する．$n$個の観測データの同時分布を$D^n$とすると，
$$
\mathbb{E}_{D^n}[\hat{R}(h)] = \frac{1}{n} \sum_{i = 1}^n \mathbb{E}_{D^n}[\ell(h(X_i), Y_i)] = \frac{1}{n} \sum_{i = 1}^n R(h) = R(h)
$$
となる．したがって，経験損失は予測損失の不偏推定量になっている．


この計算ではデータの独立性を仮定していないが，通常は独立性を仮定して経験損失と予測損失の間に成り立つ性質についてさまざまな解析を行う．
観測データが独立に同一の分布$D$に従うとき，大数の法則より$\hat{R}(h)$が$R(h)$に確率収束する．すなわち，分布$D^n$の下で任意の$\varepsilon$に対して
$$
\lim_{n \to \infty} \mathbb{P}_{D^n}\left(|\hat{R}(h) - R(h) | > \varepsilon \right) = 0
$$
が成り立つ．ここで，$\mathbb{P}_{D^n}$は$D^n$の下での確率を表す．

多くの問題は予測損失を最小化する仮説を求める問題に定式化される．正確な予測損失の値は未知だが，近似値として経験損失が分かる．
$\Rightarrow$ 経験損失を最小化することで適切な仮説を学習できると考えられる．
学習した仮説の精度を評価するためには，経験損失と予測損失の間の違いを見積もることが重要．

経験損失と予測損失の差を評価する方法から得られる知見を用いて，学習アルゴリズムによって得られる仮説に精度保証を与えたり，既存のアルゴリズムの性能を改良することなどが可能になる．